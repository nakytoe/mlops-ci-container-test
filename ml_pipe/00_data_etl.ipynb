{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp data_etl\n",
    "%load_ext autoreload\n",
    "# automatically reload (local) python modules if they are updated\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data ETL\n",
    "\n",
    "> In this notebook, load, clean, join and preprocess dev, train, test and validation data for the ML model.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***notebook input:***\n",
    "\n",
    "raw data\n",
    "\n",
    "***notebook output:***\n",
    "\n",
    "clean and tidy dataset + toy dataset for testing. Alternatively / optionally a complete ETL pipe as a function or class. \n",
    "\n",
    "***description:***\n",
    "\n",
    "In this notebook, load the data, inspect, clean and make it tidy. Define the data points and their features and labels. The output of this notebook is a clean, tidy dataset or multiple datasets, ready to use for developing, training, testing and validating machine learning with. Additionally, this is the place to perform any necessary statistical analysis and visualization for the data.\n",
    "\n",
    "You should also create basic summary statistics function for aggregating the data it's most relevant features in a meaningful manner. You can use the same function to monitor inputs and outputs with the ML model in production. The summary statistics function should be able to take in a clean dataframe and return a dataframe of the summary statistics, in the same manner as `pd.Dataframe.describe` does. However, the columns of the data and summary statistics dataframes do not need to be identical. Some examples of simple summary statistics functions can be found from `api/metrics/prometheus_metrics.py`.\n",
    "\n",
    "For any functions and classes you define for handling the data, remember to mark their cells with `# | export` to be able to export them to a module with `nbdev_export`.\n",
    "\n",
    "Rewrite this and the other text cells with your own descriptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import relevant modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define notebook parameters\n",
    "\n",
    "Define input, output and additional parameters of this notebook, the information needed for running the notebook automatically. \n",
    "\n",
    "In this cell, only assing values to variables directly: `variable_name = value`.\n",
    "**Do not derive any information in this cell as it will mess up the parameterization** - do it in the cell below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tag this cell as 'parameters' to utilise papermills notebook parameterization!\n",
    "seed = 0\n",
    "raw_data_path = \"./data/raw_data/\"\n",
    "clean_data_path = \"./data/clean_data/\"\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define any immediate derivative operations from the parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "np.random.seed(seed)\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe the data\n",
    "\n",
    "Define data points, features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data\n",
    "\n",
    "> Tip! Follow [the tidy data principles](https://vita.had.co.nz/papers/tidy-data.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suffle dataset \n",
    "\n",
    "(skip if time series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample a small sample dataset for developing\n",
    "\n",
    "Don't fail for bugs with long runs! \n",
    "\n",
    "It's far more efficient to develop with a small but realistic dataset. Create a 10-1000 data point sample to develop with.\n",
    "\n",
    "Move on to using full data when your pipe and API function and pass tests with the dev dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the dev dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
